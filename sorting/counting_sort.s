// Copyright (C) 2022 Sneller, Inc.
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

//+build !noasm !appengine

#include "../vm/bc_imm_amd64.h"

// Code generated by generator.go; DO NOT EDIT.

#define LoadKeysAndIndices      \
    MOVQ keys+0(FP), Keys       \
    MOVQ indices+8(FP), Indices


// func countingSortAscFloat64(keys *float64, indices *uint64, size int) (sorted bool)
TEXT 路countingSortAscFloat64(SB), 7, $320-25

#define Keys            SI
#define KeysEnd         R8
#define Indices         DI
#define Count           CX
#define IndicesCopy     BX

    MOVQ size+16(FP), Count

    MOVB $1, sorted+24(FP)

    CMPQ Count, $(4*8)
    JNBE not_supported

    CMPQ Count, $(3*8)
    JA sort4registers

    CMPQ Count, $(2*8)
    JA sort3registers

    CMPQ Count, $8
    JA sort2registers

    // Count = 0..8
sort1register:
    TESTQ Count, Count
    JZ    noelements

    // calculate active mask: K1 := (1 << size) - 1
    XORQ DX,    DX
    BTSQ Count, DX
    SUBQ $1,    DX
    KMOVQ DX,   K1

    LoadKeysAndIndices

    // copy indices to the stack ([8]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64 (Indices), Z0
    VMOVDQU64 Z0, (IndicesCopy)

    // zero offsets table (offsets type is byte[8])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 X0, 128(SP)

    // load keys into zmm0
    VMOVDQU64.Z (Keys), K1, Z0

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort1:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z2
    ADDQ $8, Keys

    VCMPPD $VCMP_IMM_LT_OQ, Z2, Z0, K1, K2
    KMOVW K2, R12
    POPCNTQ R12, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort1
noelements:
    VZEROUPPER
    RET

    // Count = 9..16
sort2registers:

    // calculate active mask: K1 := (1 << (size - 8)) - 1
    LEAQ -8(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([16]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64   (Indices), Z0
    VMOVDQU64 64(Indices), K1, Z1
    VMOVDQU64 Z0,   (IndicesCopy)
    VMOVDQU64 Z1, 64(IndicesCopy)

    // zero offsets table (offsets type is byte[16])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Y0, 128(SP)

    // load keys into zmm0 and zmm1
    VMOVDQU64     (Keys), Z0
    VMOVDQU64.Z 64(Keys), K1, Z1

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort2:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z2
    ADDQ $8, Keys
    VCMPPD $VCMP_IMM_LT_OQ, Z2, Z0, K2
    VCMPPD $VCMP_IMM_LT_OQ, Z2, Z1, K1, K3
    KMOVW K2, R12
    KMOVW K3, R13
    POPCNTQ R12, AX
    POPCNTQ R13, CX
    ADDQ    CX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort2
    VZEROUPPER
    RET

    // Count = 17..24
sort3registers:

    // calculate active mask: K1 := (1 << (size - 16)) - 1
    LEAQ -16(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([24]uint32)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), K1, Z2
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)

    // zero offsets table (offsets type is [24]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 192(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64.Z 128(Keys), K1, Z2

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort3:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z3
    ADDQ $8, Keys
    VCMPPD $VCMP_IMM_LT_OQ, Z3, Z0, K2
    VCMPPD $VCMP_IMM_LT_OQ, Z3, Z1, K3
    VCMPPD $VCMP_IMM_LT_OQ, Z3, Z2, K1, K4
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    ADDQ    CX, AX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    192(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort3
    VZEROUPPER
    RET

    // Count = 25..32
sort4registers:

    // calculate active mask: K1 := (1 << (size - 24)) - 1
    LEAQ -24(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([32]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), Z2
    VMOVDQU64 192(Indices), K1, Z3
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)
    VMOVDQU64 Z3, 192(IndicesCopy)

    // zero offsets table (offsets type is [32]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 256(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64   128(Keys), Z2
    VMOVDQU64.Z 192(Keys), K1, Z3

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort4:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z4
    ADDQ $8, Keys
    VCMPPD $VCMP_IMM_LT_OQ, Z4, Z0, K2
    VCMPPD $VCMP_IMM_LT_OQ, Z4, Z1, K3
    VCMPPD $VCMP_IMM_LT_OQ, Z4, Z2, K4
    VCMPPD $VCMP_IMM_LT_OQ, Z4, Z3, K1, K5
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    KMOVW K5, R9
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    POPCNTQ R9, R9
    ADDQ    CX, AX
    ADDQ    R9, DX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    256(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort4
    VZEROUPPER
    RET

not_supported:
    MOVB $0, sorted+24(FP)
    RET
#undef Keys
#undef KeysEnd
#undef Indices
#undef Count
#undef IndicesCopy

// func countingSortDescFloat64(keys *float64, indices *uint64, size int) (sorted bool)
TEXT 路countingSortDescFloat64(SB), 7, $320-25

#define Keys            SI
#define KeysEnd         R8
#define Indices         DI
#define Count           CX
#define IndicesCopy     BX

    MOVQ size+16(FP), Count

    MOVB $1, sorted+24(FP)

    CMPQ Count, $(4*8)
    JNBE not_supported

    CMPQ Count, $(3*8)
    JA sort4registers

    CMPQ Count, $(2*8)
    JA sort3registers

    CMPQ Count, $8
    JA sort2registers

    // Count = 0..8
sort1register:
    TESTQ Count, Count
    JZ    noelements

    // calculate active mask: K1 := (1 << size) - 1
    XORQ DX,    DX
    BTSQ Count, DX
    SUBQ $1,    DX
    KMOVQ DX,   K1

    LoadKeysAndIndices

    // copy indices to the stack ([8]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64 (Indices), Z0
    VMOVDQU64 Z0, (IndicesCopy)

    // zero offsets table (offsets type is byte[8])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 X0, 128(SP)

    // load keys into zmm0
    VMOVDQU64.Z (Keys), K1, Z0

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort1:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z2
    ADDQ $8, Keys

    VCMPPD $VCMP_IMM_GT_OQ, Z2, Z0, K1, K2
    KMOVW K2, R12
    POPCNTQ R12, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort1
noelements:
    VZEROUPPER
    RET

    // Count = 9..16
sort2registers:

    // calculate active mask: K1 := (1 << (size - 8)) - 1
    LEAQ -8(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([16]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64   (Indices), Z0
    VMOVDQU64 64(Indices), K1, Z1
    VMOVDQU64 Z0,   (IndicesCopy)
    VMOVDQU64 Z1, 64(IndicesCopy)

    // zero offsets table (offsets type is byte[16])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Y0, 128(SP)

    // load keys into zmm0 and zmm1
    VMOVDQU64     (Keys), Z0
    VMOVDQU64.Z 64(Keys), K1, Z1

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort2:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z2
    ADDQ $8, Keys
    VCMPPD $VCMP_IMM_GT_OQ, Z2, Z0, K2
    VCMPPD $VCMP_IMM_GT_OQ, Z2, Z1, K1, K3
    KMOVW K2, R12
    KMOVW K3, R13
    POPCNTQ R12, AX
    POPCNTQ R13, CX
    ADDQ    CX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort2
    VZEROUPPER
    RET

    // Count = 17..24
sort3registers:

    // calculate active mask: K1 := (1 << (size - 16)) - 1
    LEAQ -16(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([24]uint32)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), K1, Z2
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)

    // zero offsets table (offsets type is [24]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 192(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64.Z 128(Keys), K1, Z2

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort3:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z3
    ADDQ $8, Keys
    VCMPPD $VCMP_IMM_GT_OQ, Z3, Z0, K2
    VCMPPD $VCMP_IMM_GT_OQ, Z3, Z1, K3
    VCMPPD $VCMP_IMM_GT_OQ, Z3, Z2, K1, K4
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    ADDQ    CX, AX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    192(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort3
    VZEROUPPER
    RET

    // Count = 25..32
sort4registers:

    // calculate active mask: K1 := (1 << (size - 24)) - 1
    LEAQ -24(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([32]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), Z2
    VMOVDQU64 192(Indices), K1, Z3
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)
    VMOVDQU64 Z3, 192(IndicesCopy)

    // zero offsets table (offsets type is [32]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 256(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64   128(Keys), Z2
    VMOVDQU64.Z 192(Keys), K1, Z3

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort4:
    // count how many keys are less than this one
    VBROADCASTSD (Keys), Z4
    ADDQ $8, Keys
    VCMPPD $VCMP_IMM_GT_OQ, Z4, Z0, K2
    VCMPPD $VCMP_IMM_GT_OQ, Z4, Z1, K3
    VCMPPD $VCMP_IMM_GT_OQ, Z4, Z2, K4
    VCMPPD $VCMP_IMM_GT_OQ, Z4, Z3, K1, K5
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    KMOVW K5, R9
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    POPCNTQ R9, R9
    ADDQ    CX, AX
    ADDQ    R9, DX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    256(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort4
    VZEROUPPER
    RET

not_supported:
    MOVB $0, sorted+24(FP)
    RET
#undef Keys
#undef KeysEnd
#undef Indices
#undef Count
#undef IndicesCopy

// func countingSortAscUint64(keys *uint64, indices *uint64, size int) (sorted bool)
TEXT 路countingSortAscUint64(SB), 7, $320-25

#define Keys            SI
#define KeysEnd         R8
#define Indices         DI
#define Count           CX
#define IndicesCopy     BX

    MOVQ size+16(FP), Count

    MOVB $1, sorted+24(FP)

    CMPQ Count, $(4*8)
    JNBE not_supported

    CMPQ Count, $(3*8)
    JA sort4registers

    CMPQ Count, $(2*8)
    JA sort3registers

    CMPQ Count, $8
    JA sort2registers

    // Count = 0..8
sort1register:
    TESTQ Count, Count
    JZ    noelements

    // calculate active mask: K1 := (1 << size) - 1
    XORQ DX,    DX
    BTSQ Count, DX
    SUBQ $1,    DX
    KMOVQ DX,   K1

    LoadKeysAndIndices

    // copy indices to the stack ([8]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64 (Indices), Z0
    VMOVDQU64 Z0, (IndicesCopy)

    // zero offsets table (offsets type is byte[8])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 X0, 128(SP)

    // load keys into zmm0
    VMOVDQU64.Z (Keys), K1, Z0

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort1:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z2
    ADDQ $8, Keys

    VPCMPUQ $VPCMP_IMM_LT, Z2, Z0, K1, K2
    KMOVW K2, R12
    POPCNTQ R12, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort1
noelements:
    VZEROUPPER
    RET

    // Count = 9..16
sort2registers:

    // calculate active mask: K1 := (1 << (size - 8)) - 1
    LEAQ -8(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([16]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64   (Indices), Z0
    VMOVDQU64 64(Indices), K1, Z1
    VMOVDQU64 Z0,   (IndicesCopy)
    VMOVDQU64 Z1, 64(IndicesCopy)

    // zero offsets table (offsets type is byte[16])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Y0, 128(SP)

    // load keys into zmm0 and zmm1
    VMOVDQU64     (Keys), Z0
    VMOVDQU64.Z 64(Keys), K1, Z1

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort2:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z2
    ADDQ $8, Keys
    VPCMPUQ $VPCMP_IMM_LT, Z2, Z0, K2
    VPCMPUQ $VPCMP_IMM_LT, Z2, Z1, K1, K3
    KMOVW K2, R12
    KMOVW K3, R13
    POPCNTQ R12, AX
    POPCNTQ R13, CX
    ADDQ    CX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort2
    VZEROUPPER
    RET

    // Count = 17..24
sort3registers:

    // calculate active mask: K1 := (1 << (size - 16)) - 1
    LEAQ -16(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([24]uint32)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), K1, Z2
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)

    // zero offsets table (offsets type is [24]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 192(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64.Z 128(Keys), K1, Z2

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort3:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z3
    ADDQ $8, Keys
    VPCMPUQ $VPCMP_IMM_LT, Z3, Z0, K2
    VPCMPUQ $VPCMP_IMM_LT, Z3, Z1, K3
    VPCMPUQ $VPCMP_IMM_LT, Z3, Z2, K1, K4
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    ADDQ    CX, AX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    192(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort3
    VZEROUPPER
    RET

    // Count = 25..32
sort4registers:

    // calculate active mask: K1 := (1 << (size - 24)) - 1
    LEAQ -24(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([32]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), Z2
    VMOVDQU64 192(Indices), K1, Z3
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)
    VMOVDQU64 Z3, 192(IndicesCopy)

    // zero offsets table (offsets type is [32]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 256(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64   128(Keys), Z2
    VMOVDQU64.Z 192(Keys), K1, Z3

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort4:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z4
    ADDQ $8, Keys
    VPCMPUQ $VPCMP_IMM_LT, Z4, Z0, K2
    VPCMPUQ $VPCMP_IMM_LT, Z4, Z1, K3
    VPCMPUQ $VPCMP_IMM_LT, Z4, Z2, K4
    VPCMPUQ $VPCMP_IMM_LT, Z4, Z3, K1, K5
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    KMOVW K5, R9
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    POPCNTQ R9, R9
    ADDQ    CX, AX
    ADDQ    R9, DX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    256(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort4
    VZEROUPPER
    RET

not_supported:
    MOVB $0, sorted+24(FP)
    RET
#undef Keys
#undef KeysEnd
#undef Indices
#undef Count
#undef IndicesCopy

// func countingSortDescUint64(keys *uint64, indices *uint64, size int) (sorted bool)
TEXT 路countingSortDescUint64(SB), 7, $320-25

#define Keys            SI
#define KeysEnd         R8
#define Indices         DI
#define Count           CX
#define IndicesCopy     BX

    MOVQ size+16(FP), Count

    MOVB $1, sorted+24(FP)

    CMPQ Count, $(4*8)
    JNBE not_supported

    CMPQ Count, $(3*8)
    JA sort4registers

    CMPQ Count, $(2*8)
    JA sort3registers

    CMPQ Count, $8
    JA sort2registers

    // Count = 0..8
sort1register:
    TESTQ Count, Count
    JZ    noelements

    // calculate active mask: K1 := (1 << size) - 1
    XORQ DX,    DX
    BTSQ Count, DX
    SUBQ $1,    DX
    KMOVQ DX,   K1

    LoadKeysAndIndices

    // copy indices to the stack ([8]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64 (Indices), Z0
    VMOVDQU64 Z0, (IndicesCopy)

    // zero offsets table (offsets type is byte[8])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 X0, 128(SP)

    // load keys into zmm0
    VMOVDQU64.Z (Keys), K1, Z0

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort1:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z2
    ADDQ $8, Keys

    VPCMPUQ $VPCMP_IMM_GT, Z2, Z0, K1, K2
    KMOVW K2, R12
    POPCNTQ R12, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort1
noelements:
    VZEROUPPER
    RET

    // Count = 9..16
sort2registers:

    // calculate active mask: K1 := (1 << (size - 8)) - 1
    LEAQ -8(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([16]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64   (Indices), Z0
    VMOVDQU64 64(Indices), K1, Z1
    VMOVDQU64 Z0,   (IndicesCopy)
    VMOVDQU64 Z1, 64(IndicesCopy)

    // zero offsets table (offsets type is byte[16])
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Y0, 128(SP)

    // load keys into zmm0 and zmm1
    VMOVDQU64     (Keys), Z0
    VMOVDQU64.Z 64(Keys), K1, Z1

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort2:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z2
    ADDQ $8, Keys
    VPCMPUQ $VPCMP_IMM_GT, Z2, Z0, K2
    VPCMPUQ $VPCMP_IMM_GT, Z2, Z1, K1, K3
    KMOVW K2, R12
    KMOVW K3, R13
    POPCNTQ R12, AX
    POPCNTQ R13, CX
    ADDQ    CX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    128(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort2
    VZEROUPPER
    RET

    // Count = 17..24
sort3registers:

    // calculate active mask: K1 := (1 << (size - 16)) - 1
    LEAQ -16(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([24]uint32)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), K1, Z2
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)

    // zero offsets table (offsets type is [24]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 192(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64.Z 128(Keys), K1, Z2

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort3:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z3
    ADDQ $8, Keys
    VPCMPUQ $VPCMP_IMM_GT, Z3, Z0, K2
    VPCMPUQ $VPCMP_IMM_GT, Z3, Z1, K3
    VPCMPUQ $VPCMP_IMM_GT, Z3, Z2, K1, K4
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    ADDQ    CX, AX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    192(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort3
    VZEROUPPER
    RET

    // Count = 25..32
sort4registers:

    // calculate active mask: K1 := (1 << (size - 24)) - 1
    LEAQ -24(Count), AX
    XORQ DX,  DX
    BTSQ AX,  DX
    SUBQ $1,  DX
    KMOVQ DX, K1

    LoadKeysAndIndices

    // copy indices to the stack ([32]uint64)
    LEAQ 0(SP), IndicesCopy
    VMOVDQU64    (Indices), Z0
    VMOVDQU64  64(Indices), Z1
    VMOVDQU64 128(Indices), Z2
    VMOVDQU64 192(Indices), K1, Z3
    VMOVDQU64 Z0,    (IndicesCopy)
    VMOVDQU64 Z1,  64(IndicesCopy)
    VMOVDQU64 Z2, 128(IndicesCopy)
    VMOVDQU64 Z3, 192(IndicesCopy)

    // zero offsets table (offsets type is [32]byte)
    VPXORD Z0, Z0, Z0
    VMOVDQU32 Z0, 256(SP)

    // load keys
    VMOVDQU64      (Keys), Z0
    VMOVDQU64    64(Keys), Z1
    VMOVDQU64   128(Keys), Z2
    VMOVDQU64.Z 192(Keys), K1, Z3

    // the address of past-last item in the keys
    LEAQ (Keys)(Count*8), KeysEnd
sort4:
    // count how many keys are less than this one
    VPBROADCASTQ (Keys), Z4
    ADDQ $8, Keys
    VPCMPUQ $VPCMP_IMM_GT, Z4, Z0, K2
    VPCMPUQ $VPCMP_IMM_GT, Z4, Z1, K3
    VPCMPUQ $VPCMP_IMM_GT, Z4, Z2, K4
    VPCMPUQ $VPCMP_IMM_GT, Z4, Z3, K1, K5
    KMOVW K2, AX
    KMOVW K3, CX
    KMOVW K4, DX
    KMOVW K5, R9
    POPCNTQ AX, AX
    POPCNTQ CX, CX
    POPCNTQ DX, DX
    POPCNTQ R9, R9
    ADDQ    CX, AX
    ADDQ    R9, DX
    ADDQ    DX, AX

    // load the corresponding index
    MOVQ (IndicesCopy), R15
    ADDQ $8, IndicesCopy

    // load the number of keys equal to this one that have been already stored
    LEAQ    256(SP)(AX*1), DX
    MOVBQZX (DX), CX
    INCB    (DX)  // increment the counter to properly handle next keys equal to this one

    // adjust the offset
    ADDQ    CX, AX

    // store index at the final destination
    MOVQ  R15, (Indices)(AX*8)

    CMPQ Keys, KeysEnd
    JNE sort4
    VZEROUPPER
    RET

not_supported:
    MOVB $0, sorted+24(FP)
    RET
#undef Keys
#undef KeysEnd
#undef Indices
#undef Count
#undef IndicesCopy
