// Copyright (C) 2022 Sneller, Inc.
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

// Code generated by Ragel. DO NOT EDIT.

package elastic_proxy

import (
    "fmt"
    "strconv"
    "strings"
)

%%{
    machine querystring;

    write data;
    access lex.;
    variable p lex.p;
    variable pe lex.pe;
}%%

type queryStringLexer struct {
    data []byte
    p, pe, cs int
    ts, te, act int

    defaultOperator string
    result          qsExpression
}

func newQueryStringLexer(data []byte) *queryStringLexer {
    lex := &queryStringLexer{
        data: data,
        pe: len(data),
        defaultOperator: "OR",
    }
    %% write init;
    return lex
}

func (lex *queryStringLexer) Lex(out *yySymType) int {
    eof := lex.pe
    tok := 0
    %%{
        escaped_char = '\\' any | '\\&&' | '\\||';
        reserved_char = [&|><!(){}"~:/] | '^' | '[' | ']' | '\\' | space | '.';
        start_reserved_char = [+\-] | reserved_char;

        main := |*
            # keywords
            "AND" | "&&" => { tok = tokAnd;    fbreak; };
            "OR" | "||"  => { tok = tokOr;     fbreak; };
            "NOT" | "!"  => { tok = tokNot;    fbreak; };
            "TO"         => { tok = tokTo;     fbreak; };
            "_exists_"   => { tok = tokExists; fbreak; };

            # range start/end
            '['      => { tok, out.incl = tokRangeStart, true;  fbreak; };
            ']'      => { tok, out.incl = tokRangeEnd,   true;  fbreak; };
            '{'      => { tok, out.incl = tokRangeStart, false; fbreak; };
            '}'      => { tok, out.incl = tokRangeEnd,   false; fbreak; };

            # grouping start/end
            '('      => { tok = '('; fbreak; };
            ')'      => { tok = ')'; fbreak; };

            # misc
            '|'       => { tok = '|'; fbreak; };
            '+'       => { tok = '+'; fbreak; };
            '-'       => { tok = '-'; fbreak; };
            ':'       => { tok = ':'; fbreak; };
            '.'       => { tok = '.'; fbreak; };

            # whitespace
            space    => { };

            # operators
            ('>' | '>=' | '<' | '<=' | '=') => {
                tok, out.text = tokOperator, lex.token()
                fbreak;
            };

            # boost
            '^' ((digit* '.' digit+) | digit+) => {
                tok = tokBoost
                out.numFloat, _ = strconv.ParseFloat(lex.tokenStripped(1,0), 64)
                fbreak;
            };

            # fuzzy
            '~' digit* => {
                fuzzy := lex.tokenStripped(1,0)
                if fuzzy == "" {
                    out.numFloat = -1
                } else {
                    out.numFloat, _ = strconv.ParseFloat(fuzzy, 64)
                }
                tok = tokFuzzy;
                fbreak;
            };

            # numeric value (float)
            [+\-]? (digit* '.' digit+) => {
                tok = tokFloat
                out.numFloat, _ = strconv.ParseFloat(lex.token(), 64)
                fbreak;
            };

            # numeric value (int)
            [+\-]? digit+ => {
                tok = tokInt
                out.numInt, _ = strconv.ParseInt(lex.token(), 10, 64)
                fbreak;
            };

            # boolean value
            'true'|'TRUE' => {
                tok = tokBool
                out.boolean = true
                fbreak;
            };
            'false'|'FALSE' => {
                tok = tokBool
                out.boolean = false
                fbreak;
            };

            # unquoted text
            (escaped_char | (any - start_reserved_char)) (escaped_char | (any - reserved_char))* => {
                tok, out.text = tokAlpha, strings.ReplaceAll(lex.token(), `\`,``)
                fbreak;
            };

            # quoted text
            '"' (^'"' | '\\"')* '"' => {
                tok, out.text = tokAlphaQuoted, lex.tokenStripped(1,1)
                fbreak;
            };

            # TODO: Also support the date-math (see date_math_lexer) format

            # regular expression
            '/' (^'/' | '\\/')* '/' => {
                tok, out.text = tokAlphaRegex, lex.tokenStripped(1,1)
                fbreak;
            };
        *|;

        write exec;
    }%%

    return tok
}

func (lex *queryStringLexer) Error(e string) {
    fmt.Println("error:", e)
}

func (lex* queryStringLexer) token() string {
    return string(lex.data[lex.ts:lex.te]);
}

func (lex* queryStringLexer) tokenStripped(a, b int) string {
    return string(lex.data[lex.ts+a:lex.te-b]);
}
